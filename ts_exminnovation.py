# -*- coding: utf-8 -*-
"""TS-EXMInnovation.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LxAQjAeNktLC0Fn9k95ZG8ljygVPuQy9
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import seaborn as sns
import tensorflow as tf
import cv2, os, gc, glob
from tqdm import tqdm
from tensorflow.keras import layers, models
import keras
from keras.models import Sequential, Model
from keras.layers import Conv2D, MaxPool2D
from keras.layers import Activation, Dropout, BatchNormalization, Flatten, Dense
from tensorflow.keras.optimizers import Adam
from keras.utils import np_utils
from keras.utils.np_utils import to_categorical
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.preprocessing import LabelEncoder

dataset_dir = 'datadir'

imgpath=[]
for (dirnames, foldernames, filenames) in os.walk(dataset_dir): #get the full path name of a type of file into all subdirectories with walk
    print(dirnames,foldernames,filenames)
    for filename in filenames:
        if (filename[-3:]=='png'): #using list slicing we can fetch the last 'n' elements from list
            imgpath.append(os.path.join(dirnames, filename))

#initialize the list of image data and target labels
data=[]
target=[]
resize=150

dic={'Viral Pneumonia': 'Pneumonia', 'Normal': 'Normal', 'COVID': 'Covid-19'}

for imgpaths in tqdm(imgpath):  #tqdm is used to make terminal progress bar
    label=imgpaths.split(os.path.sep)[-2]
    image=cv2.imread(imgpaths)
    image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    image=cv2.resize(image, (resize, resize)) /255 #resizing the image


    #updates the respective data and target label lists
    data.append(image)
    target.append(dic[label])

print(len(data))

le=LabelEncoder() #labelencoder used to normalize labels
labels=le.fit_transform(target) #also be used to transform non-numerical labels to numerical labels
labels=to_categorical(labels)

print(le.classes_)
print(labels[0])

"""splting data"""

#spliting data into training and testing (80-20 Ratio)

(trainX, testX, trainY, testY)=train_test_split(data, labels, test_size=0.20, stratify=labels, random_state=42)

trainX=np.array(trainX)
testX=np.array(testX)
trainY=np.array(trainY)
testY=np.array(testY)

print(trainX.shape)
print(testX.shape)
print(trainY.shape)
print(testY.shape)

""" as example transfer Learning VGG16 model"""

from keras.applications.vgg16 import VGG16
from keras.optimizers import SGD

print(model.summary())

"""# TS-EXM

"""

def MOWNER1(image, model, layers, num_features_list, sigma=1.85):
    importance_maps = []
    for layer_name, num_features in zip(layers, num_features_list):
        layer = model.get_layer(layer_name)
        #print(layer)
        intermediate_model = tf.keras.Model(inputs=model.input, outputs=layer.output)
        #print(image)
        feature_maps = intermediate_model.predict(image)
        top_indices = np.argsort(np.mean(feature_maps, axis=(0,1,2)))[-num_features:]
        feature_maps = feature_maps[..., top_indices]
        means = np.mean(feature_maps, axis=(0,1,2))
        stds = np.std(feature_maps, axis=(0,1,2))
        binary_maps = []
        for i in range(feature_maps.shape[-1]):
            binary_map = np.zeros_like(feature_maps[:,:,:,i])
            binary_map[feature_maps[:,:,:,i] > means[i] + sigma*stds[i]] = 1
            binary_maps.append(binary_map)
        weights = means / np.sum(means)
        importance_map = np.zeros_like(feature_maps[:,:,:,-1])
        for i in range(len(binary_maps)):
            importance_map += binary_maps[i] * weights[i]
        importance_map = (importance_map - np.min(importance_map)) / (np.max(importance_map) - np.min(importance_map))
        original_size = image.shape[1:3]
        importance_map = tf.image.resize(importance_map, size=original_size, method='bilinear')
        importance_map = importance_map.numpy()[0]
        importance_maps.append(importance_map)

    return importance_maps

model = tf.keras.models.load_model('..\Vgg16_model.h5')
layer_names = ['block1_conv1', 'block5_conv3']  # List of layer names
num_features_list =[256, 512]  # List of corresponding num_features
path3 =  # Your input image
image = Image.open(path3).convert('RGB')
image = image.resize((150, 150))  # resize the image to match the model input size
image = np.array(image)
image = np.expand_dims(image, axis=0)
#print(image.shape)
importance_maps = MOWNER1(image, model, layer_names, num_features_list)


for i, importance_map in enumerate(importance_maps):
    layer_name = layer_names[i]
    plt.figure()
    plt.imshow(importance_map, cmap='jet', interpolation='nearest')
    plt.title(f'Importance Map - {layer_name}')
    plt.colorbar()
    plt.show()

""" andvanced fusion"""

def fused_map2(importance_map1, importance_map2):
    # Redimensionner les cartes d'importance pour qu'elles aient la même taille
    height, width = importance_map1.shape[:2]
    importance_map2 = cv2.resize(importance_map2, (width, height), interpolation=cv2.INTER_LINEAR)

    # Convertir les cartes d'importance en images flottantes
    importance_map1 = importance_map1.astype(np.float32)
    importance_map2 = importance_map2.astype(np.float32)

    radius = 5 # contrôle la taille de la fenêtre de filtrage
    eps = 1e-6  #contrôle la régularisation du filtre guidé. Il est utilisé pour éviter les divisions par zéro lors du calcul de la covariance locale.
    importance_map_fused = cv2.ximgproc.guidedFilter(importance_map1, importance_map2, radius, eps)

    # Normaliser la carte d'importance fusionnée entre 0 et 1
    importance_map_fused = (importance_map_fused - np.min(importance_map_fused)) / (np.max(importance_map_fused) - np.min(importance_map_fused))

    return importance_map_fused

fused_mapNew = fused_map2(importance_maps[0], importance_maps[1])

plt.figure()
plt.imshow(fused_mapNew, cmap='jet', interpolation='nearest')
plt.title('Carte d''importance fusionnée')
plt.colorbar()
plt.show()